{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 개체명 인식: NER\n",
        "- NER(Named Entity Recognition, 개체명 인식)에서는 문장 속에서 사람, 장소, 조직, 날짜 같은 의미 있는 단어들을 찾아내는 작업을 함.\n",
        "- 텍스트에서 특정 의미를 가진 단어나 구절을 찾아내고 분류하는 작업\n",
        "- 이때 단어(token)가 개체인지 표시하는 형식이 BIO 방식"
      ],
      "metadata": {
        "id": "eBXzbkDgJVBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Dz6uYEGJOa3"
      },
      "outputs": [],
      "source": [
        "# 홍길동은 2025년 11월 19일 서울시청에서 삼성전자 직원을 만났다\n",
        "# 홍길동 - [인명]\n",
        "# 2024년 1월 15일 - [날짜]\n",
        "# 서울시청 - [지명]\n",
        "# 삼성전자 - [기관명]\n",
        "\n",
        "# 활용분야\n",
        "    # 뉴스기사 : 기사에서 인물, 장소, 기관 자동 추출\n",
        "    # 의료문서 : 병명, 약물명, 증상\n",
        "    # 계약서 : 회사명, 날짜, 금액\n",
        "    # 챗봇 : 사용자 질문에 핵심정보 파악\n",
        "\n",
        "# BIO 태깅\n",
        "    # B(Begin) 개체 시작\n",
        "    # I(Inside) 개체 내부\n",
        "    # O(Outside) 개체가 아님"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "STsMPcs9Lnpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BIO 태깅\n",
        "tokens = [\"김철수는\", \"2024년\", \"1월\", \"15일\", \"서울시청에서\", \"삼성전자\", \"직원을\", \"만났다\"]\n",
        "bio_tags = [\"B-PER\", \"B-DAT\", \"I-DAT\", \"I-DAT\", \"B-LOC\", \"B-ORG\", \"O\", \"O\"]\n",
        "for token, tag in zip(tokens, bio_tags):\n",
        "    if tag.startswith('B-'):\n",
        "        desc = f\"'{tag[2:]}' 개체의 시작\"\n",
        "    elif tag.startswith('I-'):\n",
        "        desc = f\"'{tag[2:]}' 개체의 내부\"\n",
        "    else :\n",
        "        desc = \"개체가 아님\"\n",
        "    print(f\" {token:12} | {tag:8} | {desc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgvLJHHzMaQF",
        "outputId": "ff43fbe2-2589-48af-d4a5-1b2426c93010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 김철수는         | B-PER    | 'PER' 개체의 시작\n",
            " 2024년        | B-DAT    | 'DAT' 개체의 시작\n",
            " 1월           | I-DAT    | 'DAT' 개체의 내부\n",
            " 15일          | I-DAT    | 'DAT' 개체의 내부\n",
            " 서울시청에서       | B-LOC    | 'LOC' 개체의 시작\n",
            " 삼성전자         | B-ORG    | 'ORG' 개체의 시작\n",
            " 직원을          | O        | 개체가 아님\n",
            " 만났다          | O        | 개체가 아님\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터\n",
        "train_sentences = [\n",
        "    [\"김철수는\", \"서울에\", \"산다\"],\n",
        "    [\"이영희는\", \"2024년에\", \"부산으로\", \"이사했다\"],\n",
        "    [\"삼성전자는\", \"대한민국의\", \"대기업이다\"],\n",
        "    [\"박지성은\", \"축구선수다\"],\n",
        "    [\"2025년\", \"1월\", \"1일은\", \"새해다\"],\n",
        "]\n",
        "\n",
        "train_labels = [\n",
        "    [\"B-PER\", \"B-LOC\", \"O\"],\n",
        "    [\"B-PER\", \"B-DAT\", \"B-LOC\", \"O\"],\n",
        "    [\"B-ORG\", \"B-LOC\", \"O\"],\n",
        "    [\"B-PER\", \"O\"],\n",
        "    [\"B-DAT\", \"I-DAT\", \"I-DAT\", \"O\"],\n",
        "]"
      ],
      "metadata": {
        "id": "sz3--ijTNMc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import mod\n",
        "# 토크나이저\n",
        "MODEL_NAME = 'skt/kobert-base-v1'\n",
        "tokenizer=AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "text = '김철수는 서울에 산다'\n",
        "# 토크나이저\n",
        "tokens = tokenizer.tokenize(text)\n",
        "# 인코딩\n",
        "encoded = tokenizer(text, return_tensors='pt')\n",
        "encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63WjHhp6N1c_",
        "outputId": "1f46cd1f-5f72-406f-9780-b72f8261ea5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[517, 490, 494,   0, 517,   0, 491,   0, 491,   0, 517,   0,   0,   0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NER 모델 4단계로 구성\n",
        "# 1. 입력 테스트\n",
        "# 2. koBERT 인코더 : 문장의 의미를 이해\n",
        "# 3. 분류기(Linear) : 예측\n",
        "# 4. 출력 라벨 : B-PER B-LOC"
      ],
      "metadata": {
        "id": "K_Hf6DP0PC0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "class SimpleNERModel(nn.Module):\n",
        "  def __init__(self, num_labels) -> None:\n",
        "    super(SimpleNERModel, self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.bert = AutoModel.from_pretrained(MODEL_NAME)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.clf = nn.Linear(self.bert.config.hidden_size,  self.num_labels) #분류기\n",
        "  def forward(self, input_ids, attention_maks):\n",
        "    # kobert로 문자 인코딩\n",
        "    outputs = self.bert(input_ids, attention_mask=attention_maks)\n",
        "    # 마지막 은닉상태 추출\n",
        "    sequence_output =  outputs.last_hidden_state\n",
        "    # Dropout 적용\n",
        "    sequence_output = self.dropout(sequence_output)\n",
        "    # 분류기\n",
        "    logits = self.clf(sequence_output)\n",
        "    return logits\n",
        "# 라벨은 모델 라벨의 갯수 ??\n",
        "label_list = set([data for i in train_labels for data in i])\n",
        "label_list\n",
        "model = SimpleNERModel(num_labels=len(label_list))\n"
      ],
      "metadata": {
        "id": "TQ6gQnz2UCjM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}