{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr_5DP2SEf-w"
      },
      "source": [
        "#### koBART\n",
        "- https://huggingface.co/gogamza/kobart-summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# % pip install torch transformers sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "WCxa14npD7HH",
        "outputId": "898297f9-d895-4706-ce16-618e909d1b2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
            "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'TV가 없는 집도 많아지고 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다.'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "# PreTrainedTokenizerFast\n",
        "    # 자연어 텍스트를 모델이 이해할 수 있는 숫자 시퀀스로 변환하는 도구\n",
        "    # FAST 버전 : Rust 기반의 빠른 토크나이저 구현\n",
        "    # 일반 tokenizer보다 속도가 빠르고 효율적\n",
        "# BartForConditionalGeneration : \n",
        "    # BART 구조를 가진 조건부 문장 생성용 모델\n",
        "    # GPT2와 달리 요약 전용 모델\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-summarization')\n",
        "model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-summarization')\n",
        "\n",
        "text = \"과거를 떠올려보자. 방송을 보던 우리의 모습을.\\\n",
        "독보적인 매체는 TV였다. 온 가족이 둘러앉아 TV를 봤다.\\\n",
        "간혹 가족들끼리 뉴스와 드라마, 예능 프로그램을 둘러싸고 리모컨 쟁탈전이 벌어지기도  했다. \\\n",
        "각자 선호하는 프로그램을 ‘본방’으로 보기 위한 싸움이었다. \\\n",
        "TV가 한 대인지 두 대인지 여부도 그래서 중요했다. \\\n",
        "지금은 어떤가. ‘안방극장’이라는 말은 옛말이 됐다. TV가 없는 집도 많다. \\\n",
        "미디어의 혜 택을 누릴 수 있는 방법은 늘어났다. \\\n",
        "각자의 방에서 각자의 휴대폰으로, 노트북으로, 태블릿으로 콘텐츠 를 즐긴다.\"\n",
        "\n",
        "raw_input_ids = tokenizer.encode(text)\n",
        "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]))\n",
        "tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "P10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
