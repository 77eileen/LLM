{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### koBART\n",
        "- https://huggingface.co/gogamza/kobart-summarization"
      ],
      "metadata": {
        "id": "Pr_5DP2SEf-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "WCxa14npD7HH",
        "outputId": "898297f9-d895-4706-ce16-618e909d1b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
            "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TV가 없는 집도 많아지고 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-summarization')\n",
        "model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-summarization')\n",
        "\n",
        "text = \"과거를 떠올려보자. 방송을 보던 우리의 모습을.\\\n",
        "독보적인 매체는 TV였다. 온 가족이 둘러앉아 TV를 봤다.\\\n",
        "간혹 가족들끼리 뉴스와 드라마, 예능 프로그램을 둘러싸고 리모컨 쟁탈전이 벌어지기도  했다. \\\n",
        "각자 선호하는 프로그램을 ‘본방’으로 보기 위한 싸움이었다. \\\n",
        "TV가 한 대인지 두 대인지 여부도 그래서 중요했다. \\\n",
        "지금은 어떤가. ‘안방극장’이라는 말은 옛말이 됐다. TV가 없는 집도 많다. \\\n",
        "미디어의 혜 택을 누릴 수 있는 방법은 늘어났다. \\\n",
        "각자의 방에서 각자의 휴대폰으로, 노트북으로, 태블릿으로 콘텐츠 를 즐긴다.\"\n",
        "\n",
        "raw_input_ids = tokenizer.encode(text)\n",
        "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]))\n",
        "tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n"
      ]
    }
  ]
}