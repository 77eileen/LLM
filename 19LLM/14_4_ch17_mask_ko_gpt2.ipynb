{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Ko GPT2\n",
        "- https://huggingface.co/skt/kogpt2-base-v2\n",
        "--> https://github.com/SKT-AI/KoGPT2\n",
        "- ìƒê¸° git ì— ìˆëŠ” ë‚´ìš© ë³µë¶™"
      ],
      "metadata": {
        "id": "JvUS5t7M-Cud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "pad_token='<pad>', mask_token='<mask>')\n",
        "tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEfpodZX2IQt",
        "outputId": "9dcd3cb5-40a7-4aa6-909c-ba4c6003704a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['â–ì•ˆë…•',\n",
              " 'í•˜',\n",
              " 'ì„¸',\n",
              " 'ìš”.',\n",
              " 'â–í•œêµ­ì–´',\n",
              " 'â–G',\n",
              " 'P',\n",
              " 'T',\n",
              " '-2',\n",
              " 'â–ì…',\n",
              " 'ë‹ˆë‹¤.',\n",
              " 'ğŸ˜¤',\n",
              " ':)',\n",
              " 'l^o']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = 'ê·¼ìœ¡ì´ ì»¤ì§€ê¸° ìœ„í•´ì„œëŠ”'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=128,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "id": "WhOUs246-v_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t8YjlgFL_5rr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "ìœ êµ¬í•œ ì—­ì‚¬ì™€ ì „í†µì— ë¹›ë‚˜ëŠ” ìš°ë¦¬ ëŒ€í•œë¯¼êµ­ì€ 3.1ìš´ë™ìœ¼ë¡œ ê±´ë¦½ëœ ëŒ€í•œë¯¼êµ­ì„ì‹œì •ë¶€ì™€ ë²•í†µê³¼ ë¶ˆì˜ì— í•­ê±°í•œ\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        "    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "    pad_token='<pad>', mask_token='<mask>')\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "model.eval()\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n",
        "# í”„ë¡¬í”„íŠ¸ê°€ ì¤‘ìš”í•¨!!!! í•œì¤„ìš”ì•½ì´ ì•„ë‹Œ, í•µì‹¬ë‹¨ì–´ ë“±ë“±ì˜ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ë‹¬ë¼ì§€ë¯€ë¡œ.\n",
        "prompt = f'{text}\\n\\n í•œì¤„ ìš”ì•½: '\n",
        "# ì¸ì½”ë”© (í”„ë¡¬í”„íŠ¸ë¥¼ ëª¨ë¸ì— ë„£ê¸° ìœ„í•´ì„œ í† í¬ë‚˜ì´ì§•)\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "# ëª¨ë¸ ì¶”ë¡  (ìƒì„±)\n",
        "with torch.no_grad():\n",
        "    gen_ids = model.generate(input_ids,\n",
        "                            max_length=256,\n",
        "                            max_new_tokens = 100,\n",
        "                            repetition_penalty=2.0, # ê°™ì€ ë§ì„ ë°˜ë³µí•˜ì§€ ì•Šë„ë¡ ë²Œì ì„ ì¤Œ\n",
        "                            pad_token_id=tokenizer.pad_token_id, # ì›ë˜ ì´ ëª¨ë¸ì´ ê°–ê³  ìˆë˜ê²ƒ? ì¤‘ìš”í•˜ì§€ì•ŠìŒ..\n",
        "                            eos_token_id=tokenizer.eos_token_id, # ì›ë˜ ì´ ëª¨ë¸ì´ ê°–ê³  ìˆë˜ê²ƒ? ì¤‘ìš”í•˜ì§€ì•ŠìŒ..\n",
        "                            bos_token_id=tokenizer.bos_token_id, # ì›ë˜ ì´ ëª¨ë¸ì´ ê°–ê³  ìˆë˜ê²ƒ? ì¤‘ìš”í•˜ì§€ì•ŠìŒ..\n",
        "                            use_cache=True,\n",
        "                            do_sample=True, #ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ë§Œë“¤ì–´ì¤Œ\n",
        "                            temperature=0.7, #ì°½ì˜ì„± ì¡°ì • (ë‚®ì„ìˆ˜ë¡ ë³´ìˆ˜ì , ë†’ì„ìˆ˜ë¡ í™˜ê° ê°€ëŠ¥ì„± ë†’ìŒ)\n",
        "                            top_k=50 #í™•ë¥ ì ìœ¼ë¡œ ìƒìœ„ 50ê°œ ë‹¨ì–´ì¤‘ì—ì„œ ì„ íƒ\n",
        "                            )\n",
        "    generated = tokenizer.decode(gen_ids[0])\n",
        "\n",
        "    # í”„ë¡¬í”„íŠ¸ ì´í›„ì— ìƒì„±ëœ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
        "    summary = generated[len(prompt):].strip()\n",
        "    print(generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8poPXgZl_dbP",
        "outputId": "b2096069-58c4-4ca3-aa98-c3dd1516dd47"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
            "Both `max_new_tokens` (=100) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ìœ êµ¬í•œ ì—­ì‚¬ì™€ ì „í†µì— ë¹›ë‚˜ëŠ” ìš°ë¦¬ ëŒ€í•œë¯¼êµ­ì€ 3.1ìš´ë™ìœ¼ë¡œ ê±´ë¦½ëœ ëŒ€í•œë¯¼êµ­ì„ì‹œì •ë¶€ì™€ ë²•í†µê³¼ ë¶ˆì˜ì— í•­ê±°í•œ \n",
            "\n",
            "\n",
            " í•œì¤„ ìš”ì•½: | 1919ë…„ 2ì›” 25ì¼ - 1917ë…„ 11ì›” 30ì¼ 05ì›” 1ì¼ ~ 1915ë…„ 3ì›” 26ì¼ 11ì‹œ ê¸°ì¤€)\n",
            "ì¼ì œê°•ì ê¸°ì— ë…ë¦½ìš´ë™ì˜ ì£¼ì²´ì˜€ë˜ ì• êµ­ì§€ì‚¬ëŠ” ì¼ì œì˜ íƒ„ì••ìœ¼ë¡œ ì¸í•´ ëŒ€ë¶€ë¶„ ë°˜íŒŒë˜ì—ˆë‹¤.\n",
            "ì´í›„ ë…ë¦½ìœ ê³µìì™€ ìœ ì¡±ë“¤ì€ êµ­ë‚´ì— ë“¤ì–´ì™€ ë…ë¦½ìš´ë™ì„ í¼ì³¤ìœ¼ë©°, ì´ë“¤ì€ ì¼ë³¸ì˜ ì¹¨ëµìœ¼ë¡œë¶€í„° ë‚˜ë¼ë¥¼ ì§€ì¼œë‚´ëŠ”ë° í° ê³µí—Œì„ í•˜ì˜€ë‹¤.\n",
            "ì´ë“¤ì— ë§ì„œ ëŒ€í•œë¯¼êµ­ ì„ì‹œì •ë¶€ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ë…ë¦½ì„ ìœ„í•´ í—Œì‹ í–ˆê³  ê·¸ ê³µë¡œë¥¼ ì¸ì •ë°›ì•„ ê±´êµ­í›ˆì¥ ì• ì¡±ì¥ì„ ì¶”ì„œí•˜ì˜€ë‹¤.\n",
            "êµ­ê°€ë³´í›ˆì²˜ ê³µí›ˆë¡ì— ë”°ë¥´ë©´, ì´ë“¤ì˜ ê³µì ì„ ê¸°ë ¤ í›ˆì¥ 1ëª…, ëŒ€í†µë ¹ í‘œì°½ 4ëª…, êµ­ë¬´ì´ë¦¬í‘œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ê¸°ì¡´ ë¬¸ì¥ì— ìˆëŠ”ê²ƒì— ëŒ€í•´ í•˜ê³  ì‹¶ë‹¤ë©´... BERTëª¨ë¸ë¡œ. ìƒˆë¡œ ìƒì„±ë˜ëŠ”ê²Œ ì‹«ë‹¤ë©´.. (í—¤ë“œì •ë³´ê°€ ìˆì–´ì•¼í•¨)\n",
        "\n",
        "- BERTëŠ” encode\n",
        "- gptëŠ” decode\n",
        "- KobartëŠ” encode, decode ë‘˜ë‹¤ ê°€ì§€ê³  ìˆìŒ"
      ],
      "metadata": {
        "id": "undp1p51DUnA"
      }
    }
  ]
}