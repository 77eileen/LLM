{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7a3807",
   "metadata": {},
   "source": [
    "## <span style=\"color: Gold\"> **ë¬¸ì¥ ì„ë² ë”©**\n",
    "\n",
    "- Cross-Encoder : BERTë°©ì‹\n",
    "    - ë‘ ë¬¸ì¥ì„ í•œ ë²ˆì— ì…ë ¥í•´ì•¼ í•¨  \n",
    "    - ë¬¸ì¥ ìŒ 1ê°œë§ˆë‹¤ ëª¨ë¸ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì•¼ í•¨  \n",
    "    - ë¬¸ì¥ ìˆ˜ê°€ nê°œë¼ë©´ ë¹„êµ ë¹„ìš©ì´ **O(nÂ²)**  \n",
    "    - ì¦‰, ë¬¸ì„œê°€ ë§ìœ¼ë©´ ê³„ì‚°ëŸ‰ì´ í­ë°œ â†’ **ê²€ìƒ‰ ì‹œìŠ¤í…œì— ë¶€ì í•©**\n",
    "\n",
    "- Sentence-Transformers : SBERT ë°©ì‹\n",
    "    - ë¬¸ì¥ì„ **í•˜ë‚˜ì”© ë…ë¦½ì ìœ¼ë¡œ ì¸ì½”ë”©** \n",
    "    - BERT ì˜ ì¶œë ¥ì„ Poolingí•´ì„œ ê° ë¬¸ì¥ì„ **ê³ ì • ê¸¸ì´ ë²¡í„°ë¡œ ì €ì¥**  \n",
    "    - ì´í›„ ë¹„êµëŠ” **ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë§Œ ê³„ì‚°í•˜ë©´ ë¨ â†’ O(n)**  \n",
    "    - ë¹ ë¥´ê³  í™•ì¥ì„± ì¢‹ìŒ â†’ **RAG, ê²€ìƒ‰, ë¬¸ì„œ ë¶„ë¥˜ ì‹¤ë¬´ í‘œì¤€**\n",
    "\n",
    "- Pooling : í† í°ë²¡í„°ë¥¼ ë¬¸ì¥ ì˜ë¯¸ ë²¡í„°ë¡œ ìš”ì•½í•˜ëŠ”ê²Œ í’€ë§\n",
    "    - BERTëŠ” í† í°ë§ˆë‹¤ ì„ë² ë”©ì„ ë§Œë“¤ê¸° ë•Œë¬¸ì—  \n",
    "    - â†’ ì´ë¥¼ í•œ ë¬¸ì¥ì˜ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•¨  \n",
    "    - â†’ ì´ ê³¼ì •ì´ **Pooling**\n",
    "\n",
    "- Pooling ë°©ì‹ë³„ ì°¨ì´\n",
    "    - [cls] Pooling : ì²«ë²ˆì§¸ í† í°([cls])ë§Œ ì‚¬ìš© / ì†ë„ëŠ” ë¹ ë¦„ / í•˜ì§€ë§Œ ë¬¸ì¥ ì˜ë¯¸ë¥¼ ì™„ì „íˆ ë°˜ì˜í•˜ì§€ ëª»í•´ **ì •í™•ë„ ë‚®ì€ í¸**\n",
    "    - **mean pooling(ê°€ì¥ ì¤‘ìš”, ì‹¤ë¬´í‘œì¤€)** : ëª¨ë“  í† í° ì„ë² ë”©ì˜ í‰ê· ì„ ì‚¬ìš© / ì˜ë¯¸ ì•ˆì •ì , ì¡ìŒ ì ìŒ /  **SBERTì—ì„œë„ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš© â†’ ê°€ì¥ ì„±ëŠ¥ ì¢‹ìŒ**\n",
    "    - max pooling : ê° ì°¨ì›ì˜ ìµœëŒ€ê°’ ì‚¬ìš© / íŠ¹ì • íŠ¹ì§•ì„ ê°•ì¡°í•˜ëŠ” íŠ¹ì„± / í•˜ì§€ë§Œ ì¼ê´€ì„±ì´ ë–¨ì–´ì ¸ **ë¶ˆì•ˆì •í•œ ê²½ìš° ë§ìŒ**\n",
    "\n",
    "- í•œêµ­ì–´ ëª¨ë¸ í™œìš© (KR-SBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcbe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\playdata2\\miniconda3\\envs\\OPENAI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„ë² ë”© í¬ê¸° : (3, 768)\n",
      "ìœ ì‚¬ë„ í–‰ë ¬ : [[0.99999976 0.80070245 0.2832657 ]\n",
      " [0.80070245 1.0000001  0.22524579]\n",
      " [0.2832657  0.22524579 0.9999999 ]]\n"
     ]
    }
   ],
   "source": [
    "# Sentence Transfomer\n",
    "# HuggingFaceì— ë“±ë¡ëœ í•œêµ­ì–´ SBERT ëª¨ë¸ì„ ë°”ë¡œ ë¶ˆëŸ¬ì˜´\n",
    "# ì´ ëª¨ë¸ì€ ì´ë¯¸ â€œë¬¸ì¥ ì˜ë¯¸ ì„ë² ë”©â€ì„ ì˜ ë‚˜ì˜¤ë„ë¡ í•™ìŠµë¨\n",
    "# ë‚´ë¶€ì ìœ¼ë¡œëŠ”:\n",
    "    # Transformer(klue-roberta-base ê³„ì—´)\n",
    "    # Mean Pooling\n",
    "    # NLI, STS ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹\n",
    "    # ì´ëŸ° ê³¼ì •ì´ ì´ë¯¸ ë˜ì–´ ìˆìŒ.\n",
    "\n",
    "# âœ”ï¸ SBERTì—ì„œ í•˜ëŠ” ì¼\n",
    "# BERTê°€ ë§Œë“  í† í° ë²¡í„°ë“¤ì„ Pooling(mean/cls/max) í•´ì„œ â†’ **\"í•˜ë‚˜ì˜ ê³ ì • ê¸¸ì´ ë¬¸ì¥ ë²¡í„°\"**ë¡œ ë§Œë“ ë‹¤.\n",
    "# [ë‚˜ëŠ”] â†’ token embedding\n",
    "# [ì˜¤ëŠ˜] â†’ token embedding\n",
    "# [ê¸°ë¶„ì´] â†’ token embedding\n",
    "# [ì¢‹ë‹¤] â†’ token embedding\n",
    "# â¡ SBERTì—ì„œëŠ” ì´ê±¸ Poolingí•´ì„œ\n",
    "# ë¬¸ì¥ ì„ë² ë”©(1ê°œ ë²¡í„°) â†’ 768ì°¨ì›\n",
    "# \"Poolingí•´ì„œ ê³ ì • í¬ê¸° ë¬¸ì¥ ë²¡í„°ë¥¼ ë§Œë“ ë‹¤\"ëŠ” ê²ƒì€ SBERT ë°©ì‹ì´ë©°, Sentence-Transformersì˜ í•µì‹¬ ë™ì‘ì´ë‹¤.\n",
    "# BERT ë‹¨ë…ìœ¼ë¡œëŠ” ë¬¸ì¥ ë²¡í„°ë¥¼ ë§Œë“¤ì§€ ì•ŠëŠ”ë‹¤.\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "sentences = [\n",
    "    'ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ìš”',\n",
    "    'ì˜¤ëŠ˜ í•˜ëŠ˜ì´ ë§‘ì•„ìš”',\n",
    "    'í”„ë¡œê·¸ë¨ì„ ë°°ìš°ê³  ì‹¶ìŠµë‹ˆë‹¤'\n",
    "]\n",
    "embeddings = model.encode(sentences)  # ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸3ê°œë¥¼ ì „ë‹¬\n",
    "print(f'ì„ë² ë”© í¬ê¸° : {embeddings.shape}') # ê° ë¬¸ì¥ì„ 768ì°¨ì›ì˜ ë²¡í„°ë¡œ ë³€í™˜\n",
    "\n",
    "# ìœ ì‚¬ë„ ê³„ì‚°\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim = cosine_similarity(embeddings)\n",
    "print ( f'ìœ ì‚¬ë„ í–‰ë ¬ : {sim}')  # ë¬¸ì¥ê°„ ì˜ë¯¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•¨\n",
    "\n",
    "# ì¶œë ¥ ìœ ì‚¬ë„ í–‰ë ¬ í•´ì„\n",
    "# ë¬¸ì¥1 ì— ëŒ€í•œ : ë¬¸ì¥1 - ë¬¸ì¥2 - ë¬¸ì¥3 ê°„ì˜ ì˜ë¯¸ ìœ ì‚¬ë„\n",
    "# ë¬¸ì¥2 ì— ëŒ€í•œ ; ë¬¸ì¥1 - ë¬¸ì¥2 - ë¬¸ì¥3 ê°„ì˜ ì˜ë¯¸ ìœ ì‚¬ë„\n",
    "# ë¬¸ì¥3 ì— ëŒ€í•œ ; ë¬¸ì¥1 - ë¬¸ì¥2 - ë¬¸ì¥3 ê°„ì˜ ì˜ë¯¸ ìœ ì‚¬ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047bc54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„ë² ë”© í¬ê¸° : (3, 768)\n",
      "ìœ ì‚¬ë„ í–‰ë ¬ : [[0.9999999  0.91393733 0.68440783]\n",
      " [0.91393733 0.99999976 0.7117275 ]\n",
      " [0.68440783 0.7117275  0.99999976]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Transformerë¥¼ ì§ì ‘ ë¶ˆëŸ¬ì™€ì„œ ì»¤ìŠ¤í…€ SBERT ë§Œë“¤ê¸°\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "transformer = models.Transformer('klue/roberta-base')  # ì´ ëª¨ë¸ì€ ë¬¸ì¥-> í† í° ì„ë² ë”©ë§Œ í•´ì¤Œ (ë¬¸ì¥ ì „ì²´ ì„ë² ë”©ì€ ì—†ìŒ)\n",
    "\n",
    "\n",
    "# pooling ë ˆì´ì–´ ì¶”ê°€\n",
    "# âœ”ï¸ í•µì‹¬ í¬ì¸íŠ¸: SBERTëŠ” Poolingì´ ìƒëª…ì„\n",
    "# BERTëŠ” ê° í† í°ë§ˆë‹¤ ë²¡í„°ë¥¼ ë§Œë“¤ê¸° ë•Œë¬¸ì—\n",
    "# â†’ ë¬¸ì¥ ë²¡í„°ë¥¼ ë§Œë“¤ë ¤ë©´ Pooling í•„ìš”\n",
    "# ì„¤ì • ë‚´ìš©:\n",
    "# mean poolingë§Œ True â†’ ì „ì²´ í† í° í‰ê·  ë²¡í„° ì‚¬ìš©\n",
    "# CLS í† í°ì€ ì‚¬ìš© X\n",
    "# Max poolingë„ ì‚¬ìš© X\n",
    "# ğŸ‘‰ ì‹¤ë¬´ì—ì„œ ê°€ì¥ ìì£¼ ì“°ëŠ” ì„¤ì •\n",
    "# ğŸ‘‰ ë¬¸ì¥ ì˜ë¯¸ë¥¼ ê°€ì¥ ì•ˆì •ì ìœ¼ë¡œ ì˜ í‘œí˜„\n",
    "\n",
    "pooling = models.Pooling(\n",
    "    transformer.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens= True, # mean pooling ì‚¬ìš©\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ì¡°ë¦½\n",
    "model = SentenceTransformer(modules=[transformer, pooling])  # Transformer (í† í° ì„ë² ë”©), #Pooling (ë¬¸ì¥ ì„ë² ë”©)\n",
    "\n",
    "# ë¬¸ì¥ ì„ë² ë”© ìƒì„±\n",
    "sentences = [\n",
    "    'ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ìš”',\n",
    "    'ì˜¤ëŠ˜ í•˜ëŠ˜ì´ ë§‘ì•„ìš”',\n",
    "    'í”„ë¡œê·¸ë¨ì„ ë°°ìš°ê³  ì‹¶ìŠµë‹ˆë‹¤'\n",
    "]\n",
    "embeddings= model.encode(sentences)\n",
    "print(f'ì„ë² ë”© í¬ê¸° : {embeddings.shape}')\n",
    "\n",
    "\n",
    "# ìœ ì‚¬ë„ ê³„ì‚°\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim = cosine_similarity(embeddings)\n",
    "print ( f'ìœ ì‚¬ë„ í–‰ë ¬ : {sim}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPENAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
