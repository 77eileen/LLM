{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r 20251127_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3befb71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예제 Document 객체\n",
      "page_content: 이것은 예제 문서의 내용입이다.\n",
      "page_metadata: {'source': 'example.txt', 'page': 1, 'author': '홍길동'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (RecursiveCharacterTextSplitter, CharacterTextSplitter)\n",
    "\n",
    "# 샘플 Document 객체 생성\n",
    "example_doc = Document(\n",
    "    page_content= '이것은 예제 문서의 내용입이다.',\n",
    "    metadata = {'source' : 'example.txt', 'page':1, 'author':'홍길동'}\n",
    ")\n",
    "print('예제 Document 객체')\n",
    "print(f'page_content: {example_doc.page_content}')\n",
    "print(f'page_metadata: {example_doc.metadata}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be22081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 분할기\n",
      "원본 문서길이 : 485자\n",
      "CharacterTextSplitter 결과 : 4개 청크\n",
      "청크별 미리보기\n",
      "chunk 1 ( 185자 : LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발을 위한 프레임워크입니다.         LangChain의 주요 구성 요소:         1. Models: 다양한 LLM 제공자(OpenAI, Anthropic, Google 등)와 통합         2. Prompts: 프롬프트 템플릿 관리 및 최적화)\n",
      "chunk 2 ( 148자 : 2. Prompts: 프롬프트 템플릿 관리 및 최적화         3. Chains: 여러 구성 요소를 연결하는 파이프라인         4. Memory: 대화 맥락을 유지하기 위한 메모리 시스템         5. Indexes: 문서 검색을 위한 인덱싱 도구)\n",
      "chunk 3 ( 189자 : 5. Indexes: 문서 검색을 위한 인덱싱 도구         6. Agents: 도구를 사용하여 복잡한 작업을 수행하는 에이전트         LangChain Expression Language (LCEL)은 체인을 구성하는 선언적 방식으로,         파이프(|) 연산자를 사용하여 컴포넌트들을 직관적으로 연결할 수 있습니다.)\n",
      "chunk 4 ( 41자 : 파이프(|) 연산자를 사용하여 컴포넌트들을 직관적으로 연결할 수 있습니다.)\n"
     ]
    }
   ],
   "source": [
    "# 샘플 문서 생성 (외부문서 시뮬레이션)\n",
    "sample_documents = [\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발을 위한 프레임워크입니다.\n",
    "        \n",
    "        LangChain의 주요 구성 요소:\n",
    "        1. Models: 다양한 LLM 제공자(OpenAI, Anthropic, Google 등)와 통합\n",
    "        2. Prompts: 프롬프트 템플릿 관리 및 최적화\n",
    "        3. Chains: 여러 구성 요소를 연결하는 파이프라인\n",
    "        4. Memory: 대화 맥락을 유지하기 위한 메모리 시스템\n",
    "        5. Indexes: 문서 검색을 위한 인덱싱 도구\n",
    "        6. Agents: 도구를 사용하여 복잡한 작업을 수행하는 에이전트\n",
    "        \n",
    "        LangChain Expression Language (LCEL)은 체인을 구성하는 선언적 방식으로,\n",
    "        파이프(|) 연산자를 사용하여 컴포넌트들을 직관적으로 연결할 수 있습니다.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"langchain_intro.txt\", \"topic\": \"framework\", \"importance\": \"high\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        RAG (Retrieval-Augmented Generation)는 검색 증강 생성 기술입니다.\n",
    "        \n",
    "        RAG의 작동 원리:\n",
    "        1. 사용자 질문을 임베딩 벡터로 변환합니다.\n",
    "        2. 벡터 데이터베이스에서 유사한 문서를 검색합니다.\n",
    "        3. 검색된 문서를 컨텍스트로 사용하여 LLM이 답변을 생성합니다.\n",
    "        \n",
    "        RAG의 장점:\n",
    "        - 최신 정보를 반영할 수 있습니다. LLM의 학습 데이터 이후 정보도 활용 가능합니다.\n",
    "        - 환각(Hallucination)을 감소시킵니다. 실제 문서 기반으로 답변하기 때문입니다.\n",
    "        - 출처를 명시할 수 있습니다. 어떤 문서에서 정보를 가져왔는지 추적 가능합니다.\n",
    "        - 도메인 특화가 가능합니다. 특정 분야의 문서만 사용하여 전문적인 답변을 제공합니다.\n",
    "        \n",
    "        RAG의 핵심 구성요소: Retriever(검색기), Generator(생성기), VectorStore(벡터저장소)\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"rag_concept.txt\", \"topic\": \"technique\", \"importance\": \"high\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        VectorDB(벡터 데이터베이스)는 고차원 벡터를 효율적으로 저장하고 검색하는 데이터베이스입니다.\n",
    "        \n",
    "        주요 VectorDB 솔루션:\n",
    "        - ChromaDB: 로컬 개발에 적합한 오픈소스 솔루션. 파이썬 네이티브로 설치가 간편합니다.\n",
    "        - Pinecone: 완전 관리형 클라우드 서비스. 대규모 프로덕션 환경에 적합합니다.\n",
    "        - Weaviate: 그래프 기반 벡터 데이터베이스. 하이브리드 검색을 지원합니다.\n",
    "        - FAISS: Facebook에서 개발한 고성능 라이브러리. 대용량 벡터 검색에 최적화되어 있습니다.\n",
    "        - Milvus: 분산 환경을 지원하는 오픈소스 솔루션입니다.\n",
    "        \n",
    "        임베딩(Embedding)은 텍스트를 숫자 벡터로 변환하는 과정으로,\n",
    "        의미적으로 유사한 텍스트는 벡터 공간에서 가까운 위치에 배치됩니다.\n",
    "        예를 들어, \"고양이\"와 \"강아지\"는 \"자동차\"보다 벡터 공간에서 더 가깝습니다.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"vectordb_intro.txt\", \"topic\": \"database\", \"importance\": \"medium\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# 텍스트 분할기\n",
    "print('텍스트 분할기')\n",
    "\n",
    "# 단순 문자기반 분할기\n",
    "char_spl = CharacterTextSplitter(\n",
    "    separator='\\n', #분할기준\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 70,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "# 첫번째 문서로 테스트\n",
    "test_doc = sample_documents[0]\n",
    "char_splits = char_spl.split_documents( [test_doc] )\n",
    "print(f'원본 문서길이 : {len(test_doc.page_content)}자')\n",
    "print(f'CharacterTextSplitter 결과 : {len(char_splits)}개 청크')\n",
    "print(f'청크별 미리보기')\n",
    "for i, chunk in enumerate(char_splits[:],1):  # [:3] 청크3개만 봄 / 전부보려면 [:] 이렇게 쓰던가, 아예 삭제해도됨\n",
    "    preview = chunk.page_content.strip()[:].replace('\\n', ' ')  # [:80] 이렇게하면 80자만 print 출력됨. / 전부보려면 [:]이렇게 쓰던가, 아예 삭제해도됨\n",
    "    print(f'chunk {i} ( {len(chunk.page_content)}자 : {preview})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter\n",
    "print('RecursiveCharacterTextSplitter 적용')\n",
    "recursive_spl = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap=50,\n",
    "    separators=['\\n', '\\n\\n', '.', ',', ' '],\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "\n",
    "# 모든 문서를 청크로 분할\n",
    "doc_rec_splits = recursive_spl.split_documents(sample_documents)\n",
    "print(f'원본 문서길이 : {len(sample_documents)}개')\n",
    "print(f'RecursiveCharacterTextSplitter 결과 : {len(doc_rec_splits)}개 청크')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b065bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveCharacterTextSplitter 적용\n",
      "원본 문서길이 : 501자\n",
      "RecursiveCharacterTextSplitter 결과 : 4개 청크\n"
     ]
    }
   ],
   "source": [
    "############ DJ 개인#########\n",
    "# RecursiveCharacterTextSplitter\n",
    "print('RecursiveCharacterTextSplitter 적용')\n",
    "recursive_spl = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap=70,\n",
    "    separators=['\\n', '\\n\\n', '.', ',', ' '],\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "\n",
    "# 첫번째 문서로 테스트\n",
    "test_doc_2 = sample_documents[0]\n",
    "doc_rec_splits = recursive_spl.split_documents([test_doc_2])\n",
    "print(f'원본 문서길이 : {len(test_doc_2.page_content)}자')\n",
    "print(f'RecursiveCharacterTextSplitter 결과 : {len(doc_rec_splits)}개 청크')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e21166f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장완료 / 파일명 : chunks_output_4_2_RAG2.pkl / 청크수 : 6\n"
     ]
    }
   ],
   "source": [
    "# 청킹 결과 저장 (pickle 사용)\n",
    "import pickle\n",
    "# 최종 분할설정 (중간크기)\n",
    "final_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap=50,\n",
    "    separators=['\\n', '\\n\\n', '.', ',', ' '],\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "final_chunks = final_splitter.split_documents(sample_documents)\n",
    "\n",
    "# 파일로 저장\n",
    "output_path = 'chunks_output_4_2_RAG2.pkl'\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(final_chunks, f)\n",
    "print(f'저장완료 / 파일명 : {output_path} / 청크수 : {len(final_chunks)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
